
Use Cases

    1a. lwfm middleware is deployed to a node within the enterprise and is scaled to support the size of the compute cluster (number of nodes, frequency of hits).  it supports jobs running on all HPC and other enterprise servers.  
        
    1b. the enterprise middleware can be used for local user jobs 
    
    1c. the enterprise middleware can be used for type 3 workflows initiated from within an enterprise type 2 workflow.
    
    1d. the enterprise middleware can be used for type 3 workflows initiated locality by the user.
    
    1e. type 3 workflows in which the remote job may call back on the enterprise middleware are permitted.
    
    1f. type 3 workflows in which the remote job may not call back on the enterprise middleware are only permitted.  here the remote site may have its own copy of the middleware, thus import/export is utilized.


    2a. lwfm middleware (MetaRepo, EventProcessor, optional GUI) is deployed by the user in the scope of user and other compute servers as if they were their own enterprise - see use case 1.

    2b. lwfm middleware can be deployed in lightweight singleton user or process-launched instances, or scaled enterprise instances

    3a. A -> B -> C use case 
        synchronous: make & run A and wait for it, then repeat for B and then C
            # run job B after job A
            jobA = makeJob(A)
            jobA.submit()
            jobA.wait()
            # repeat for B and C
            jobB = makeJob(B)  etc.

    3b. asynchronous control flow: downstream jobs B and C may or may not have control and/or data flow dependencies; if they have no control flow dependency, they can be run simultaneous.  if they have a control flow dependency A triggers B.  
            jobA = makeJob(A)
            jobB = makeJob(B)
            setJobTrigger(jobB, jobA)
            jobA.submit()

    3c. asynchronous join: same as a control flow dependency, but B is dependent on a set of upstream A 
            jobA1 = makeJob(A)
            jobA2 = makeJob(A)
            jobB = makeJob(B)
            setJobTrigger(jobB, [jobA1, jobA2])
            jobA1.submit()
            jobA2.submit()

    3d. asynchronous data flow: if two jobs have a data flow dependency, the creation of data with a metadata signature (potentially but not necessarily by job A) triggers the running of B.
